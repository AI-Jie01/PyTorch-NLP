


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; PyTorch-NLP 0.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="#"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="PyTorch-NLP 0.0.0 documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> PyTorch-NLP
          

          
          </a>

          
            
            
              <div class="version">
                0.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.html">torchnlp package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="source/torchnlp.datasets.html">torchnlp.datasets package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.count">torchnlp.datasets.count module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.dataset">torchnlp.datasets.dataset module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.reverse">torchnlp.datasets.reverse module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.simple_qa">torchnlp.datasets.simple_qa module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.zero_to_zero">torchnlp.datasets.zero_to_zero module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="source/torchnlp.metrics.html">torchnlp.metrics package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.metrics.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics.accuracy">torchnlp.metrics.accuracy module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics.bleu">torchnlp.metrics.bleu module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="source/torchnlp.nn.html">torchnlp.nn package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.nn.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn.attention">torchnlp.nn.attention module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn.lock_dropout">torchnlp.nn.lock_dropout module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="source/torchnlp.samplers.html">torchnlp.samplers package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.bucket_batch_sampler">torchnlp.samplers.bucket_batch_sampler module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.noisy_sorted_sampler">torchnlp.samplers.noisy_sorted_sampler module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.random_batch_sampler">torchnlp.samplers.random_batch_sampler module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.sorted_sampler">torchnlp.samplers.sorted_sampler module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="source/torchnlp.text_encoders.html">torchnlp.text_encoders package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.character_encoder">torchnlp.text_encoders.character_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.delimiter_encoder">torchnlp.text_encoders.delimiter_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.identity_encoder">torchnlp.text_encoders.identity_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.moses_encoder">torchnlp.text_encoders.moses_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.reserved_tokens">torchnlp.text_encoders.reserved_tokens module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.spacy_encoder">torchnlp.text_encoders.spacy_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.static_tokenizer_encoder">torchnlp.text_encoders.static_tokenizer_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_encoder">torchnlp.text_encoders.subword_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_text_tokenizer">torchnlp.text_encoders.subword_text_tokenizer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.text_encoders">torchnlp.text_encoders.text_encoders module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.treebank_encoder">torchnlp.text_encoders.treebank_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.word_encoder">torchnlp.text_encoders.word_encoder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.html#module-torchnlp.pretrained_embeddings">torchnlp.pretrained_embeddings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.html#module-torchnlp.utils">torchnlp.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.html#module-torchnlp">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.datasets.html">torchnlp.datasets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.count">torchnlp.datasets.count module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.dataset">torchnlp.datasets.dataset module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.reverse">torchnlp.datasets.reverse module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.simple_qa">torchnlp.datasets.simple_qa module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets.zero_to_zero">torchnlp.datasets.zero_to_zero module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.datasets.html#module-torchnlp.datasets">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.metrics.html">torchnlp.metrics package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.metrics.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics.accuracy">torchnlp.metrics.accuracy module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics.bleu">torchnlp.metrics.bleu module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.metrics.html#module-torchnlp.metrics">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.nn.html">torchnlp.nn package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.nn.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn.attention">torchnlp.nn.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn.lock_dropout">torchnlp.nn.lock_dropout module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.nn.html#module-torchnlp.nn">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.samplers.html">torchnlp.samplers package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.bucket_batch_sampler">torchnlp.samplers.bucket_batch_sampler module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.noisy_sorted_sampler">torchnlp.samplers.noisy_sorted_sampler module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.random_batch_sampler">torchnlp.samplers.random_batch_sampler module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers.sorted_sampler">torchnlp.samplers.sorted_sampler module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.samplers.html#module-torchnlp.samplers">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/torchnlp.text_encoders.html">torchnlp.text_encoders package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.character_encoder">torchnlp.text_encoders.character_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.delimiter_encoder">torchnlp.text_encoders.delimiter_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.identity_encoder">torchnlp.text_encoders.identity_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.moses_encoder">torchnlp.text_encoders.moses_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.reserved_tokens">torchnlp.text_encoders.reserved_tokens module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.spacy_encoder">torchnlp.text_encoders.spacy_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.static_tokenizer_encoder">torchnlp.text_encoders.static_tokenizer_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_encoder">torchnlp.text_encoders.subword_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_text_tokenizer">torchnlp.text_encoders.subword_text_tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.text_encoders">torchnlp.text_encoders.text_encoders module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.treebank_encoder">torchnlp.text_encoders.treebank_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.word_encoder">torchnlp.text_encoders.word_encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders">Module contents</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyTorch-NLP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Index</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.nn.html#torchnlp.nn.Attention">Attention (class in torchnlp.nn)</a>

      <ul>
        <li><a href="source/torchnlp.nn.html#torchnlp.nn.attention.Attention">(class in torchnlp.nn.attention)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.BucketBatchSampler">BucketBatchSampler (class in torchnlp.samplers)</a>

      <ul>
        <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.bucket_batch_sampler.BucketBatchSampler">(class in torchnlp.samplers.bucket_batch_sampler)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.build_from_corpus">build_from_corpus() (torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.build_from_token_counts">build_from_token_counts() (torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer method)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.build_to_target_size_from_corpus">build_to_target_size_from_corpus() (torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer class method)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.build_to_target_size_from_token_counts">build_to_target_size_from_token_counts() (torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer class method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.CharacterEncoder">CharacterEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.character_encoder.CharacterEncoder">(class in torchnlp.text_encoders.character_encoder)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.CharNGram">CharNGram (class in torchnlp.pretrained_embeddings)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.count_dataset">count_dataset() (in module torchnlp.datasets)</a>

      <ul>
        <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.count.count_dataset">(in module torchnlp.datasets.count)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.Dataset">Dataset (class in torchnlp.datasets)</a>

      <ul>
        <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.dataset.Dataset">(class in torchnlp.datasets.dataset)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.decode">decode() (in module torchnlp.text_encoders.subword_text_tokenizer)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.CharacterEncoder.decode">(torchnlp.text_encoders.CharacterEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.DelimiterEncoder.decode">(torchnlp.text_encoders.DelimiterEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.IdentityEncoder.decode">(torchnlp.text_encoders.IdentityEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.MosesEncoder.decode">(torchnlp.text_encoders.MosesEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.StaticTokenizerEncoder.decode">(torchnlp.text_encoders.StaticTokenizerEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.SubwordEncoder.decode">(torchnlp.text_encoders.SubwordEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.TreebankEncoder.decode">(torchnlp.text_encoders.TreebankEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.WordEncoder.decode">(torchnlp.text_encoders.WordEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.character_encoder.CharacterEncoder.decode">(torchnlp.text_encoders.character_encoder.CharacterEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.delimiter_encoder.DelimiterEncoder.decode">(torchnlp.text_encoders.delimiter_encoder.DelimiterEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.identity_encoder.IdentityEncoder.decode">(torchnlp.text_encoders.identity_encoder.IdentityEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.moses_encoder.MosesEncoder.decode">(torchnlp.text_encoders.moses_encoder.MosesEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder.decode">(torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_encoder.SubwordEncoder.decode">(torchnlp.text_encoders.subword_encoder.SubwordEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.decode">(torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.text_encoders.TextEncoder.decode">(torchnlp.text_encoders.text_encoders.TextEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.treebank_encoder.TreebankEncoder.decode">(torchnlp.text_encoders.treebank_encoder.TreebankEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.word_encoder.WordEncoder.decode">(torchnlp.text_encoders.word_encoder.WordEncoder method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.DelimiterEncoder">DelimiterEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.delimiter_encoder.DelimiterEncoder">(class in torchnlp.text_encoders.delimiter_encoder)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.encode">encode() (in module torchnlp.text_encoders.subword_text_tokenizer)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.StaticTokenizerEncoder.encode">(torchnlp.text_encoders.StaticTokenizerEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.SubwordEncoder.encode">(torchnlp.text_encoders.SubwordEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder.encode">(torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_encoder.SubwordEncoder.encode">(torchnlp.text_encoders.subword_encoder.SubwordEncoder method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.encode">(torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer method)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.text_encoders.TextEncoder.encode">(torchnlp.text_encoders.text_encoders.TextEncoder method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.FastText">FastText (class in torchnlp.pretrained_embeddings)</a>
</li>
      <li><a href="source/torchnlp.nn.html#torchnlp.nn.Attention.forward">forward() (torchnlp.nn.Attention method)</a>

      <ul>
        <li><a href="source/torchnlp.nn.html#torchnlp.nn.LockedDropout.forward">(torchnlp.nn.LockedDropout method)</a>
</li>
        <li><a href="source/torchnlp.nn.html#torchnlp.nn.attention.Attention.forward">(torchnlp.nn.attention.Attention method)</a>
</li>
        <li><a href="source/torchnlp.nn.html#torchnlp.nn.lock_dropout.LockedDropout.forward">(torchnlp.nn.lock_dropout.LockedDropout method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.get_accuracy">get_accuracy() (in module torchnlp.metrics)</a>

      <ul>
        <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.accuracy.get_accuracy">(in module torchnlp.metrics.accuracy)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.get_moses_multi_bleu">get_moses_multi_bleu() (in module torchnlp.metrics)</a>

      <ul>
        <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.bleu.get_moses_multi_bleu">(in module torchnlp.metrics.bleu)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.get_token_accuracy">get_token_accuracy() (in module torchnlp.metrics)</a>

      <ul>
        <li><a href="source/torchnlp.metrics.html#torchnlp.metrics.accuracy.get_token_accuracy">(in module torchnlp.metrics.accuracy)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.GloVe">GloVe (class in torchnlp.pretrained_embeddings)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.IdentityEncoder">IdentityEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.identity_encoder.IdentityEncoder">(class in torchnlp.text_encoders.identity_encoder)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.nn.html#torchnlp.nn.LockedDropout">LockedDropout (class in torchnlp.nn)</a>

      <ul>
        <li><a href="source/torchnlp.nn.html#torchnlp.nn.lock_dropout.LockedDropout">(class in torchnlp.nn.lock_dropout)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.MosesEncoder">MosesEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.moses_encoder.MosesEncoder">(class in torchnlp.text_encoders.moses_encoder)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.CharNGram.name">name (torchnlp.pretrained_embeddings.CharNGram attribute)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.native_to_unicode">native_to_unicode() (in module torchnlp.text_encoders.subword_text_tokenizer)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.native_to_unicode_py2">native_to_unicode_py2() (in module torchnlp.text_encoders.subword_text_tokenizer)</a>
</li>
      <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.NoisySortedSampler">NoisySortedSampler (class in torchnlp.samplers)</a>

      <ul>
        <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.noisy_sorted_sampler.NoisySortedSampler">(class in torchnlp.samplers.noisy_sorted_sampler)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.RandomBatchSampler">RandomBatchSampler (class in torchnlp.samplers)</a>

      <ul>
        <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.random_batch_sampler.RandomBatchSampler">(class in torchnlp.samplers.random_batch_sampler)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.html#torchnlp.utils.reporthook">reporthook() (in module torchnlp.utils)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.html#torchnlp.utils.resplit_datasets">resplit_datasets() (in module torchnlp.utils)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.reverse_dataset">reverse_dataset() (in module torchnlp.datasets)</a>

      <ul>
        <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.reverse.reverse_dataset">(in module torchnlp.datasets.reverse)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.simple_qa_dataset">simple_qa_dataset() (in module torchnlp.datasets)</a>

      <ul>
        <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.simple_qa.simple_qa_dataset">(in module torchnlp.datasets.simple_qa)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.SortedSampler">SortedSampler (class in torchnlp.samplers)</a>

      <ul>
        <li><a href="source/torchnlp.samplers.html#torchnlp.samplers.sorted_sampler.SortedSampler">(class in torchnlp.samplers.sorted_sampler)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.SpacyEncoder">SpacyEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.spacy_encoder.SpacyEncoder">(class in torchnlp.text_encoders.spacy_encoder)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.StaticTokenizerEncoder">StaticTokenizerEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder">(class in torchnlp.text_encoders.static_tokenizer_encoder)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.SubwordEncoder">SubwordEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_encoder.SubwordEncoder">(class in torchnlp.text_encoders.subword_encoder)</a>
</li>
      </ul></li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer">SubwordTextTokenizer (class in torchnlp.text_encoders.subword_text_tokenizer)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.text_encoders.TextEncoder">TextEncoder (class in torchnlp.text_encoders.text_encoders)</a>
</li>
      <li><a href="source/torchnlp.html#torchnlp.utils.torch_equals_ignore_index">torch_equals_ignore_index() (in module torchnlp.utils)</a>
</li>
      <li><a href="source/torchnlp.html#module-torchnlp">torchnlp (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets">torchnlp.datasets (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets.count">torchnlp.datasets.count (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets.dataset">torchnlp.datasets.dataset (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets.reverse">torchnlp.datasets.reverse (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets.simple_qa">torchnlp.datasets.simple_qa (module)</a>
</li>
      <li><a href="source/torchnlp.datasets.html#module-torchnlp.datasets.zero_to_zero">torchnlp.datasets.zero_to_zero (module)</a>
</li>
      <li><a href="source/torchnlp.metrics.html#module-torchnlp.metrics">torchnlp.metrics (module)</a>
</li>
      <li><a href="source/torchnlp.metrics.html#module-torchnlp.metrics.accuracy">torchnlp.metrics.accuracy (module)</a>
</li>
      <li><a href="source/torchnlp.metrics.html#module-torchnlp.metrics.bleu">torchnlp.metrics.bleu (module)</a>
</li>
      <li><a href="source/torchnlp.nn.html#module-torchnlp.nn">torchnlp.nn (module)</a>
</li>
      <li><a href="source/torchnlp.nn.html#module-torchnlp.nn.attention">torchnlp.nn.attention (module)</a>
</li>
      <li><a href="source/torchnlp.nn.html#module-torchnlp.nn.lock_dropout">torchnlp.nn.lock_dropout (module)</a>
</li>
      <li><a href="source/torchnlp.html#module-torchnlp.pretrained_embeddings">torchnlp.pretrained_embeddings (module)</a>
</li>
      <li><a href="source/torchnlp.samplers.html#module-torchnlp.samplers">torchnlp.samplers (module)</a>
</li>
      <li><a href="source/torchnlp.samplers.html#module-torchnlp.samplers.bucket_batch_sampler">torchnlp.samplers.bucket_batch_sampler (module)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.samplers.html#module-torchnlp.samplers.noisy_sorted_sampler">torchnlp.samplers.noisy_sorted_sampler (module)</a>
</li>
      <li><a href="source/torchnlp.samplers.html#module-torchnlp.samplers.random_batch_sampler">torchnlp.samplers.random_batch_sampler (module)</a>
</li>
      <li><a href="source/torchnlp.samplers.html#module-torchnlp.samplers.sorted_sampler">torchnlp.samplers.sorted_sampler (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders">torchnlp.text_encoders (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.character_encoder">torchnlp.text_encoders.character_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.delimiter_encoder">torchnlp.text_encoders.delimiter_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.identity_encoder">torchnlp.text_encoders.identity_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.moses_encoder">torchnlp.text_encoders.moses_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.reserved_tokens">torchnlp.text_encoders.reserved_tokens (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.spacy_encoder">torchnlp.text_encoders.spacy_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.static_tokenizer_encoder">torchnlp.text_encoders.static_tokenizer_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_encoder">torchnlp.text_encoders.subword_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.subword_text_tokenizer">torchnlp.text_encoders.subword_text_tokenizer (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.text_encoders">torchnlp.text_encoders.text_encoders (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.treebank_encoder">torchnlp.text_encoders.treebank_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#module-torchnlp.text_encoders.word_encoder">torchnlp.text_encoders.word_encoder (module)</a>
</li>
      <li><a href="source/torchnlp.html#module-torchnlp.utils">torchnlp.utils (module)</a>
</li>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.TreebankEncoder">TreebankEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.treebank_encoder.TreebankEncoder">(class in torchnlp.text_encoders.treebank_encoder)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.unicode_to_native">unicode_to_native() (in module torchnlp.text_encoders.subword_text_tokenizer)</a>
</li>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.CharNGram.url">url (torchnlp.pretrained_embeddings.CharNGram attribute)</a>

      <ul>
        <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.GloVe.url">(torchnlp.pretrained_embeddings.GloVe attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.html#torchnlp.pretrained_embeddings.FastText.url_base">url_base (torchnlp.pretrained_embeddings.FastText attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder.vocab">vocab (torchnlp.text_encoders.static_tokenizer_encoder.StaticTokenizerEncoder attribute)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.StaticTokenizerEncoder.vocab">(torchnlp.text_encoders.StaticTokenizerEncoder attribute)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.SubwordEncoder.vocab">(torchnlp.text_encoders.SubwordEncoder attribute)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_encoder.SubwordEncoder.vocab">(torchnlp.text_encoders.subword_encoder.SubwordEncoder attribute)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.vocab">(torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer attribute)</a>
</li>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.text_encoders.TextEncoder.vocab">(torchnlp.text_encoders.text_encoders.TextEncoder attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer.vocab_size">vocab_size (torchnlp.text_encoders.subword_text_tokenizer.SubwordTextTokenizer attribute)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.text_encoders.TextEncoder.vocab_size">(torchnlp.text_encoders.text_encoders.TextEncoder attribute)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.WordEncoder">WordEncoder (class in torchnlp.text_encoders)</a>

      <ul>
        <li><a href="source/torchnlp.text_encoders.html#torchnlp.text_encoders.word_encoder.WordEncoder">(class in torchnlp.text_encoders.word_encoder)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.zero_to_zero_dataset">zero_to_zero_dataset() (in module torchnlp.datasets)</a>

      <ul>
        <li><a href="source/torchnlp.datasets.html#torchnlp.datasets.zero_to_zero.zero_to_zero_dataset">(in module torchnlp.datasets.zero_to_zero)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>



           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Michael Petrochuk.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>